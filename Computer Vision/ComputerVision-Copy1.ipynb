{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using https://www.pyimagesearch.com/2016/02/15/determining-object-color-with-opencv/ to work coordinates for tokens based on colour.\n",
    "\n",
    "https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/ for downloading packages in Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install --upgrade imutils\n",
    "# !{sys.executable} -m pip install --upgrade opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image, convert it to grayscale, blur it slightly,\n",
    "# and threshold it\n",
    "image = cv2.imread('board3.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.pyimagesearch.com/2014/08/04/opencv-python-color-detection/ using to mask the image to only deal with parts of a certain colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([100, 0, 0], dtype = \"uint8\") # BGR\n",
    "upper = np.array([255, 100, 100], dtype = \"uint8\")\n",
    "\n",
    "# find the colors within the specified boundaries and apply\n",
    "# the mask\n",
    "mask = cv2.inRange(image, lower, upper)\n",
    "image = cv2.bitwise_and(image, image, mask = mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each element has the form (x,y,area)\n",
    "blobs = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.0\n",
      "192.5\n",
      "2261.0\n",
      "2100.5\n",
      "7.0\n",
      "6.5\n",
      "1.0\n",
      "17.5\n",
      "4.5\n",
      "3.0\n",
      "116.0\n",
      "42.0\n",
      "2.5\n",
      "86.5\n",
      "332.0\n",
      "114.0\n",
      "0.5\n",
      "1.5\n",
      "0.5\n",
      "1.0\n",
      "47.5\n",
      "10.0\n",
      "3.0\n",
      "512.5\n",
      "1.5\n",
      "722.0\n",
      "768.0\n",
      "26.0\n",
      "92.0\n"
     ]
    }
   ],
   "source": [
    "# Our image is already white on black, but we apply grayscale\n",
    "# again, blur the image for better detection and then apply\n",
    "# a threshold.\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# Contours are a curve that joins all the continous points\n",
    "# around an object with a specific colour intensity.\n",
    "# in openCV this is finding white objects on a black background.\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    # compute the center of the contour\n",
    "    M = cv2.moments(c) # Weighted average of pixel intensities\n",
    "    \n",
    "    # Computing the coordinates of the centre of each token.\n",
    "    # Coordinates are relative to the image.\n",
    "    # So they are on a 1200 by 720 grid.\n",
    "    \n",
    "    # Small amount of the colour picked up, ignore as no area so\n",
    "    # will not be a token.\n",
    "    if M[\"m00\"] == 0: continue\n",
    "    \n",
    "    x = int(M[\"m10\"] / M[\"m00\"])\n",
    "    y = int(M[\"m01\"] / M[\"m00\"])\n",
    "    \n",
    "    blobs = blobs + [(x,y,M[\"m00\"])]\n",
    "    print(str(M[\"m00\"]))\n",
    " \n",
    "    # Code off of the internet that can plot the contours.\n",
    "    cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "    cv2.circle(image, (x, y), 7, (255, 255, 255), -1)\n",
    "    cv2.putText(image, \"center\", (x - 20, y - 20),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapes(image,lower, upper):\n",
    "    # From RGB to BGR\n",
    "    lower.reverse()\n",
    "    upper.reverse()\n",
    "    \n",
    "    lower = np.array(lower, dtype = \"uint8\")\n",
    "    upper = np.array(upper, dtype = \"uint8\")\n",
    "    \n",
    "    # find the colors within the specified boundaries and apply the mask\n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "    image = cv2.bitwise_and(image, image, mask = mask)\n",
    "    \n",
    "    # Each element has the form (x,y,area)\n",
    "    xs = [];\n",
    "    ys = [];\n",
    "    areas = []; \n",
    "    \n",
    "    # Our image is already white on black, but we apply grayscale\n",
    "    # again, blur the image for better detection and then apply\n",
    "    # a threshold.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Contours are a curve that joins all the continous points\n",
    "    # around an object with a specific colour intensity.\n",
    "    # in openCV this is finding white objects on a black background.\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    \n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # compute the center of the contour\n",
    "        M = cv2.moments(c) # Weighted average of pixel intensities\n",
    "    \n",
    "        # Computing the coordinates of the centre of each token.\n",
    "        # Coordinates are relative to the image.\n",
    "        # So they are on a 1200 by 720 grid.\n",
    "    \n",
    "        # Small amount of the colour picked up, ignore as no area so\n",
    "        # will not be a token.\n",
    "        if M[\"m00\"] == 0: continue\n",
    "        \n",
    "        xs += [M[\"m10\"] / M[\"m00\"]]\n",
    "        ys += [M[\"m01\"] / M[\"m00\"]]\n",
    "        areas += [M[\"m00\"]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = int(M[\"m10\"] / M[\"m00\"])\n",
    "        y = int(M[\"m01\"] / M[\"m00\"])\n",
    "        \n",
    "        # Code off of the internet that can plot the contours.\n",
    "        cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "        cv2.circle(image, (x, y), 7, (255, 255, 255), -1)\n",
    "        cv2.putText(image, \"center\", (x - 20, y - 20),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "    \n",
    "    cv2.imshow(\"cam-test\",image)\n",
    "    cv2.waitKey(10)\n",
    "\n",
    "    return np.row_stack((xs,ys,areas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c4392bfc3985>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Creating a matrix each column contains details of a token (x,y,area,colour)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mblack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblack\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"B\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mwhite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"W\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblack\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwhite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Getting all of the black tokens\n",
    "black = get_shapes(image,[0,0,140],[100,100,255])\n",
    "# Getting all of the white tokens\n",
    "white = get_shapes(image,[140,0,0],[255,100,100])\n",
    "\n",
    "# Creating a matrix each column contains details of a token (x,y,area,colour)\n",
    "black = np.row_stack(black,np.array([\"B\"] * np.shape[0]))\n",
    "white = np.row_stack(white,np.array([\"W\"] * np.shape[0]))\n",
    "tokens = np.hstack((black,white))\n",
    "\n",
    "x_inds = np.digitize(tokens[0], 13 / 22 * np.arange(1,12))\n",
    "y_inds = np.digitize(tokens[1], [8/22, 14/22])\n",
    "\n",
    "knocked_out = []\n",
    "board = [[]] * 24\n",
    "\n",
    "for (s,x,y) in zip(tokens,x_inds,y_inds):\n",
    "    if y == 1 or x == 6: # Middle section of the board\n",
    "        knocked_out += [s]\n",
    "    elif y == 0:\n",
    "        board[x] += s\n",
    "    else:\n",
    "        board[23-x] += s\n",
    "\n",
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    cam = cv2.VideoCapture(1)   # 0 -> index of camera\n",
    "    retrieved, image = cam.read()\n",
    "    #image = cv2.imread('board5.jpg')\n",
    "    if retrieved:\n",
    "        #shapes = get_shapes(image,[0,0,100],[100,100,255])\n",
    "        shapes = get_shapes(image,[95,220,95],[180,255,180])\n",
    "        #v2.imshow(\"cam-test\",image)\n",
    "        #cv2.waitKey(10)\n",
    "    else:\n",
    "        print(\"Error reading from webcam\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0.5, 1.25, 2.75, 4.24, 19.25])\n",
    "bins = np.array([0.0, 1.0, 2.5, 4.0, 10.0])\n",
    "inds = np.digitize(x, bins)\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('board.jpg',image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
